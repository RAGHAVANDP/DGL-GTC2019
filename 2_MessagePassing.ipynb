{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Message Passing with DGL\n",
    "=====================\n",
    "\n",
    "In previous tutorial (1_Basics.ipynb), we studied the basic usage of DGL like creating and manipulating a DGLGraph. In this tutorial, we will focus on how to perform computation on graph structures following Message Passing paradigm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit of setup, just ignore this cell\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8.0, 6.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['animation.html'] = 'html5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we  still use karate club as example. And we provide a utility function to create the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl, torch\n",
    "import networkx as nx\n",
    "from tutorial_utils import create_karate_graph\n",
    "G = create_karate_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.dropbox.com/s/uqzor4lqsmbnz8k/karate1.jpg?dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Message passing on graph\n",
    "-------------------------------------------------\n",
    "\n",
    "Many graph neural networks follows the **message passing** computation model ([Gilmer et al, 2017](https://arxiv.org/abs/1704.01212)):\n",
    "- each node receives and aggregates messages from its neighbors  \n",
    "$$m_v^{t+1} = \\sum\\limits_{w\\in N(v)}M_t(h_v^t, h_w^t, e_{vw}^t)$$\n",
    "\n",
    "- each node update its own embedding using aggregated messages\n",
    "$$h_v^{t+1} = U_t(h_v^t, m_v^{t+1})$$\n",
    "\n",
    "We will go through the basic mechanism of message passing using a toy task:\n",
    "\n",
    "Suppose the karate club president (node 33) is sending out an invitation of their annual karate match. The president also asks the club members to broadcast the news to, of course, their friends in the club. We use a scalar to represent whether the member has received the invitation or not (1 for invited, 0 for not invited). Initially, everyone is 0 except node 33."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first convert the uni-directional edges to bi-directional so messages can\n",
    "#   be sent in both direction.\n",
    "src, dst = G.edges()\n",
    "G.add_edges(dst, src)\n",
    "# add self loop for each nodes for convenience\n",
    "v = G.nodes()\n",
    "G.add_edges(v, v)\n",
    "print('We now have %d edges!' % G.number_of_edges())\n",
    "\n",
    "# init the state\n",
    "G.ndata['invited'] = torch.zeros((34,))\n",
    "G.nodes[33].data['invited'] = torch.tensor([1.])\n",
    "print(G.ndata['invited'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the function that computes the messages. In DGL, the message function is an **Edge UDF** that takes in a single argument `edges`. It has three members `src`, `dst`, and `data` for accessing source node features, destination node features, and edge features respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_func(edges):\n",
    "    # The message is simply the 'invited' state of the source nodes.\n",
    "    return {'msg' : edges.src['invited']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the reduce function which accumulates and consume the messages to update the node features. In DGL, the reduce function is a **Node UDF** that takes in a single argument `nodes`, which has two members `data` and `mailbox`. `data` contains the node features while `mailbox` contains all incoming message features, stacked along the second dimension (hence the `dim=1` argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_func(nodes):\n",
    "    # The reduce function sets the 'invited' state to be one if the node has already\n",
    "    #   been invited or any of the received messages contains an invitation (is one).\n",
    "    #   This can be done using sum and clamp operations as follows.\n",
    "    accum = nodes.mailbox['msg'].sum(dim=1)  # note that messages are stacked on dim=1\n",
    "    return {'invited' : accum.clamp(max=1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To trigger the message and reduce function, one can use the `send` and `recv` APIs. Following codes send out the messages from node 33:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first argument to `G.send` is the edges along which the messages are sent.\n",
    "# Note that we can use the same syntax used in adding edges to the graph.\n",
    "# The second argument is the message function we just defined.\n",
    "G.send((33, G.successors(33)), message_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then call `recv` on the receiver nodes to trigger the reduce function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.recv(G.successors(33), reduce_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print out the `'invited'` status to see the invitation being propagated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G.ndata['invited'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What's under the hood?**\n",
    "\n",
    "The key idea here is to automatically batch the node and edge features so that your UDF can compute message passing on multiple nodes and edges in parallel.\n",
    "\n",
    "```python\n",
    "def message_func(edges):\n",
    "    return {'msg' : edges.src['invited']}\n",
    "```\n",
    "\n",
    "The `edges` argument is an `EdgeBatch` object representing a batch of edges. It has three members, `src`, `dst`, `data`. The `edges.src['invited']` returns a tensor of shape `(B,)`, where `B` is the number of edges being triggered.\n",
    "\n",
    "```python\n",
    "def reduce_func(nodes):\n",
    "    accum = nodes.mailbox['msg'].sum(dim=1)\n",
    "    return {'invited' : accum.clamp(max=1)}\n",
    "```\n",
    "\n",
    "Similarly, for the reduce function, the argument `nodes` is an `NodeBatch` object representing a batch of nodes. It has two members `data` and `mailbox`. The `nodes.mailbox['msg']` returns a tensor of shape `(B, deg)`, where `B` is the number of nodes that have the same in-degree `deg`. The reduce function will be called *many times* for each degree group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: please write code to continue broadcasting the invitation until all members in the graph are invited.\n",
    "\n",
    "#Hint 1: you can always trigger message function on all edges and reduce function on all nodes\n",
    "#Hint 2: you can get all edges with G.edges() and all nodes with G.nodes()\n",
    "\n",
    "num_invited = int(torch.sum(G.ndata['invited']))\n",
    "while num_invited != 34:\n",
    "    \n",
    "    # >>> YOUR CODE START\n",
    "\n",
    "    \n",
    "    \n",
    "    # <<< YOUR CODE END\n",
    "    \n",
    "    num_invited = int(torch.sum(G.ndata['invited']))\n",
    "    print('%d members have been invited.' % num_invited)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
